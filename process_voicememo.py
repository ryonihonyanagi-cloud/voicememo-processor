#!/usr/bin/env python3
"""
Voice Memo Processor v2.1
  Phase 1: USB mount â†’ WAV to MP3 â†’ Google Drive (date folders)
  Phase 2: Google Drive MP3 â†’ mlx-whisper local â†’ GPT-4o summary â†’ Markdown

Changes from v2:
- Anti-hallucination: condition_on_previous_text=False, hallucination_silence_threshold
- Post-processing filter for repetitive/hallucinated segments
- macOS push notifications for progress tracking
"""

import json
import logging
import os
import re
import shutil
import subprocess
import tempfile
import time
from collections import defaultdict
from datetime import datetime
from pathlib import Path

import dotenv
import mlx_whisper
import openai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VOICEMEMO_MOUNT = Path(os.environ.get(
    "VOICEMEMO_MOUNT", 
    "/Volumes/VOICEMEMO/RECORD"
))
FFMPEG_PATH = shutil.which("ffmpeg") or "/opt/homebrew/bin/ffmpeg"
FFPROBE_PATH = shutil.which("ffprobe") or "/opt/homebrew/bin/ffprobe"

MARKDOWN_OUTPUT_DIR = Path(os.environ.get(
    "MARKDOWN_OUTPUT_DIR",
    str(Path.home() / "Documents/GitHub/llm-knowledge-base/0-inbox/voicememo")
))
MP3_BASE_DIR = Path(os.environ.get(
    "MP3_BASE_DIR",
    str(Path.home() / "Library/CloudStorage/GoogleDrive-ryo.nihonyanagi@10xc.jp/ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–/Voicememo")
))

SCRIPT_DIR = Path(__file__).parent.resolve()
MANIFEST_PATH = SCRIPT_DIR / "processed_files.json"
STATUS_PATH = SCRIPT_DIR / "status.json"
USER_PROFILE_PATH = SCRIPT_DIR / "user_profile.json"  # Accumulating persona context
LOG_DIR = SCRIPT_DIR / "logs"
STAGING_DIR = SCRIPT_DIR / "staging"  # Local MP3 copies to avoid FUSE deadlock

MP3_BITRATE = "64k"
WHISPER_MODEL_REPO = "mlx-community/whisper-large-v3-turbo"
GPT_MODEL = "gpt-4o"

# File naming: 2026-02-11-17-53-58.WAV
FILENAME_PATTERN = re.compile(
    r"(\d{4})-(\d{2})-(\d{2})-(\d{2})-(\d{2})-(\d{2})\.(WAV|mp3)", re.IGNORECASE
)

logger = logging.getLogger("voicememo")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# User Profile (Context Accumulation for SNS Posts)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_user_profile() -> dict:
    """Load or initialize the user profile for context-aware SNS post generation."""
    if USER_PROFILE_PATH.exists():
        try:
            return json.loads(USER_PROFILE_PATH.read_text(encoding="utf-8"))
        except Exception:
            pass
    return {
        "frequent_topics": [],          # Topics that come up often (accumulated)
        "tone_description": "",          # Writing tone/style inferred from posts
        "example_posts": [],             # Last N successful/generated posts (for style reference)
        "interests": [],                 # Inferred interest areas
        "last_updated": ""
    }


def save_user_profile(profile: dict):
    """Persist the updated user profile."""
    import datetime
    profile["last_updated"] = datetime.datetime.now().isoformat()
    USER_PROFILE_PATH.write_text(json.dumps(profile, ensure_ascii=False, indent=2), encoding="utf-8")


def update_user_profile(client, date: str, summary_data: dict, profile: dict) -> dict:
    """Ask GPT-4o to merge today's insights into the running user profile."""
    new_posts = summary_data.get("x_threads_posts", [])
    new_topics = summary_data.get("deep_conversations", [])
    today_summary = summary_data.get("summary", "")

    # Keep a rolling window of the 20 most recent posts as style examples
    all_posts = profile.get("example_posts", []) + [
        p.get("content", "") for p in new_posts if p.get("content")
    ]
    profile["example_posts"] = all_posts[-20:]

    # Ask GPT to update the topic list and tone description
    topics_block = "\n".join(
        f"- {dc.get('topic', '')}: {dc.get('insight', '')}" for dc in new_topics
    )
    examples_block = "\n".join(f"- {p}" for p in all_posts[-5:])

    update_prompt = f"""ã‚ãªãŸã¯SNSæŠ•ç¨¿ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã‚’æ‹…å½“ã™ã‚‹AIã§ã™ã€‚
ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºä¿¡ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ã‚ˆãèªã‚‹ãƒ†ãƒ¼ãƒã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚

ã€ä»Šæ—¥ã®æ—¥ä»˜ã€‘{date}
ã€ä»Šæ—¥ã®ã‚µãƒãƒªãƒ¼ã€‘{today_summary}

ã€ä»Šæ—¥ã®æ·±ã„ä¼šè©±ãƒ»æ°—ã¥ãã€‘
{topics_block}

ã€éå»ã®æŠ•ç¨¿ä¾‹ï¼ˆæœ€è¿‘ã®ã‚‚ã®ï¼‰ã€‘
{examples_block}

ã€ç¾åœ¨ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€‘
ã‚ˆãèªã‚‹ãƒ†ãƒ¼ãƒ: {', '.join(profile.get('frequent_topics', []))}
æ–‡ä½“ãƒ»ãƒˆãƒ¼ãƒ³: {profile.get('tone_description', '(æœªè¨­å®š)')}
èˆˆå‘³ãƒ»é–¢å¿ƒ: {', '.join(profile.get('interests', []))}

ä»¥ä¸‹ã®JSONå½¢å¼ã§æ›´æ–°ã•ã‚ŒãŸãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„:
{{
  "frequent_topics": ["ãƒ†ãƒ¼ãƒ1", "ãƒ†ãƒ¼ãƒ2", ...],  // ä»Šæ—¥ã®å†…å®¹ã‚‚è¸ã¾ãˆã€é‡è¦åº¦ãŒé«˜ã„é †ã«æœ€å¤§15ä»¶
  "tone_description": "ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ–‡ä½“ãƒ»ç™ºä¿¡ã‚¹ã‚¿ã‚¤ãƒ«ã®èª¬æ˜ï¼ˆ3ã€œ5æ–‡ï¼‰",
  "interests": ["é–¢å¿ƒé ˜åŸŸ1", "é–¢å¿ƒé ˜åŸŸ2", ...]   // ä¸»ãªé–¢å¿ƒé ˜åŸŸã€æœ€å¤§10ä»¶
}}

ãƒ«ãƒ¼ãƒ«:
- frequent_topicsã¯ä»Šæ—¥æ–°ãŸã«ç™»å ´ã—ãŸãƒ†ãƒ¼ãƒã‚‚è¿½åŠ ã—ã¦ãã ã•ã„
- æ—¢å­˜ã®ãƒ†ãƒ¼ãƒã¨é‡è¤‡ã™ã‚‹ã‚‚ã®ã¯ã¾ã¨ã‚ã¦ãã ã•ã„
- tone_descriptionã¯éå»ã®æŠ•ç¨¿ä¾‹ã‹ã‚‰æ–‡ä½“ãƒ»ãƒˆãƒ¼ãƒ³ãƒ»è¨€è‘‰é¸ã³ã®å‚¾å‘ã‚’æå†™ã—ã¦ãã ã•ã„
- å…¨ã¦æ—¥æœ¬èª"""

    try:
        result = _call_summary_api(client, update_prompt)
        if isinstance(result, dict):
            if result.get("frequent_topics"):
                profile["frequent_topics"] = result["frequent_topics"]
            if result.get("tone_description"):
                profile["tone_description"] = result["tone_description"]
            if result.get("interests"):
                profile["interests"] = result["interests"]
    except Exception as e:
        logger.warning(f"  Profile update failed (non-critical): {e}")

    return profile


def _build_profile_context(profile: dict) -> str:
    """Format the user profile as a context block for injection into prompts."""
    if not profile.get("frequent_topics") and not profile.get("tone_description"):
        return ""  # No profile yet â€” first run
    parts = []
    if profile.get("frequent_topics"):
        parts.append(f"ã‚ˆãèªã‚‹ãƒ†ãƒ¼ãƒ: {', '.join(profile['frequent_topics'][:10])}")
    if profile.get("interests"):
        parts.append(f"é–¢å¿ƒé ˜åŸŸ: {', '.join(profile['interests'][:6])}")
    if profile.get("tone_description"):
        parts.append(f"æ–‡ä½“ãƒ»ãƒˆãƒ¼ãƒ³: {profile['tone_description']}")
    if profile.get("example_posts"):
        examples = profile["example_posts"][-3:]
        parts.append("éå»ã®æŠ•ç¨¿ä¾‹:")
        for ex in examples:
            parts.append(f"  - {ex[:120]}{'...' if len(ex) > 120 else ''}")
    return "\n".join(parts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# macOS Notifications
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def notify(title: str, message: str, sound: str = ""):
    """Send a macOS notification via osascript."""
    try:
        sound_part = f' sound name "{sound}"' if sound else ""
        script = (
            f'display notification "{message}" '
            f'with title "{title}"{sound_part}'
        )
        subprocess.Popen(
            ["osascript", "-e", script],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )
    except Exception:
        pass  # Notifications are best-effort, never block processing


def update_status(
    status: str = "idle",
    phase: int = 0,
    phase_label: str = "",
    current_file: str = "",
    files_total: int = 0,
    files_completed: int = 0,
    last_error: str | None = None,
):
    """Write current processing status to status.json for the menu bar monitor."""
    try:
        data = {
            "status": status,
            "phase": phase,
            "phase_label": phase_label,
            "current_file": current_file,
            "files_total": files_total,
            "files_completed": files_completed,
            "last_error": last_error,
            "last_updated": datetime.now().isoformat(),
        }
        tmp = STATUS_PATH.with_suffix(".tmp")
        tmp.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
        tmp.replace(STATUS_PATH)
    except Exception:
        pass  # Status updates are best-effort


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Logging
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def setup_logging():
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    log_file = LOG_DIR / f"voicememo-{datetime.now().strftime('%Y%m%d')}.log"

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8"),
            logging.StreamHandler(),
        ],
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Manifest (processed files tracking)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def load_manifest() -> dict:
    if MANIFEST_PATH.exists():
        return json.loads(MANIFEST_PATH.read_text(encoding="utf-8"))
    return {"version": 2, "copied": {}, "transcribed": {}}


def save_manifest(manifest: dict):
    MANIFEST_PATH.write_text(
        json.dumps(manifest, indent=2, ensure_ascii=False), encoding="utf-8"
    )


def migrate_manifest(manifest: dict) -> dict:
    """Migrate v1 manifest to v2 format if needed."""
    if manifest.get("version") == 2:
        return manifest

    new_manifest = {"version": 2, "copied": {}, "transcribed": {}}

    # Migrate v1 "processed" entries
    for filename, entry in manifest.get("processed", {}).items():
        mp3_name = filename.replace(".WAV", ".mp3").replace(".wav", ".mp3")

        # Mark as copied
        new_manifest["copied"][filename] = {
            "size_bytes": entry.get("size_bytes", 0),
            "copied_at": entry.get("processed_at", ""),
            "mp3_name": mp3_name,
            "date": entry.get("date", ""),
            "time": entry.get("time", ""),
            "time_full": entry.get("time_full", ""),
        }

        # If it was fully transcribed, mark that too
        if entry.get("status") == "completed" and "transcript_text" in entry:
            new_manifest["transcribed"][mp3_name] = {
                "transcribed_at": entry.get("processed_at", ""),
                "duration_seconds": entry.get("duration_seconds", 0),
                "date": entry.get("date", ""),
                "time": entry.get("time", ""),
                "time_full": entry.get("time_full", ""),
                "transcript_text": entry.get("transcript_text", ""),
                "segments": entry.get("segments", []),
            }

    return new_manifest


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Phase 1: USB â†’ MP3 â†’ Google Drive
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def discover_wav_files() -> list[dict]:
    """Scan USB device for WAV files."""
    files = []
    for wav_path in sorted(VOICEMEMO_MOUNT.glob("*.WAV")):
        match = FILENAME_PATTERN.match(wav_path.name)
        if match:
            y, m, d, hh, mm, ss, _ext = match.groups()
            files.append(
                {
                    "path": wav_path,
                    "filename": wav_path.name,
                    "date": f"{y}-{m}-{d}",
                    "time": f"{hh}:{mm}",
                    "time_full": f"{hh}:{mm}:{ss}",
                    "size": wav_path.stat().st_size,
                }
            )
    return files


def convert_wav_to_mp3(wav_path: Path, mp3_path: Path) -> Path:
    """Convert WAV to MP3 using ffmpeg."""
    mp3_path.parent.mkdir(parents=True, exist_ok=True)
    cmd = [
        FFMPEG_PATH,
        "-y",
        "-i",
        str(wav_path),
        "-vn",
        "-ac", "1",
        "-ar", "16000",
        "-acodec", "libmp3lame",
        "-b:a", MP3_BITRATE,
        str(mp3_path),
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
    if result.returncode != 0:
        raise RuntimeError(f"ffmpeg conversion failed: {result.stderr[-500:]}")
    return mp3_path


def _copy_to_google_drive(src_path: Path, dest_path: Path):
    """Copy a file to Google Drive using raw byte write (avoids fcopyfile deadlock).

    Write-only operation â€” Google Drive FUSE handles writes fine,
    the deadlock only occurs on reads while Drive is syncing.
    """
    dest_path.parent.mkdir(parents=True, exist_ok=True)
    with open(src_path, "rb") as src, open(dest_path, "wb") as dst:
        while True:
            chunk = src.read(1024 * 1024)
            if not chunk:
                break
            dst.write(chunk)


def phase1_copy_from_usb(manifest: dict) -> set[str]:
    """
    Phase 1: Convert WAV files from USB to MP3.
    Saves to local staging dir first (for reliable Phase 2 reads),
    then copies to Google Drive (for backup/sync).
    Returns set of dates that had new files copied.
    """
    if not VOICEMEMO_MOUNT.exists():
        logger.info("VOICEMEMO not mounted, skipping Phase 1")
        return set()

    wav_files = discover_wav_files()
    new_files = [
        f for f in wav_files
        if f["filename"] not in manifest["copied"]
    ]

    if not new_files:
        logger.info("Phase 1: No new WAV files on device")
        return set()

    logger.info(f"Phase 1: {len(new_files)} new WAV file(s) to convert")
    notify("Voice Memo", f"Phase 1: {len(new_files)}ä»¶ã®WAVã‚’å¤‰æ›ä¸­...")
    update_status("processing", 1, "MP3å¤‰æ›ä¸­", files_total=len(new_files))
    new_dates = set()

    STAGING_DIR.mkdir(parents=True, exist_ok=True)

    for i, file_info in enumerate(new_files, 1):
        filename = file_info["filename"]
        date = file_info["date"]
        mp3_name = filename.replace(".WAV", ".mp3").replace(".wav", ".mp3")

        # Convert to local staging first (fast, reliable local disk)
        staging_path = STAGING_DIR / mp3_name

        # Google Drive: organized by date folder
        gdrive_path = MP3_BASE_DIR / date / mp3_name

        logger.info(f"  Converting: {filename}")
        notify("Voice Memo", f"MP3å¤‰æ›ä¸­ ({i}/{len(new_files)}): {filename}")
        update_status("processing", 1, "MP3å¤‰æ›ä¸­", filename, len(new_files), i - 1)

        try:
            # Step 1: Convert WAV â†’ MP3 to local staging
            convert_wav_to_mp3(file_info["path"], staging_path)
            mp3_size_mb = staging_path.stat().st_size / (1024 * 1024)
            logger.info(f"  â†’ {staging_path.name} ({mp3_size_mb:.1f} MB) [staging]")

            # Step 2: Copy to Google Drive (write-only, non-blocking)
            try:
                _copy_to_google_drive(staging_path, gdrive_path)
                logger.info(f"  â†’ Copied to Google Drive: {gdrive_path.parent.name}/{gdrive_path.name}")
            except OSError as e:
                # Google Drive write failure is non-fatal â€” staging copy is enough
                logger.warning(f"  Google Drive copy failed (will retry later): {e}")

            manifest["copied"][filename] = {
                "size_bytes": file_info["size"],
                "copied_at": datetime.now().isoformat(),
                "mp3_name": mp3_name,
                "mp3_path": str(gdrive_path),
                "staging_path": str(staging_path),
                "date": date,
                "time": file_info["time"],
                "time_full": file_info["time_full"],
            }
            save_manifest(manifest)
            new_dates.add(date)

        except Exception as e:
            logger.error(f"  FAILED converting {filename}: {e}")
            update_status("processing", 1, "MP3å¤‰æ›ä¸­", filename, len(new_files), i - 1, last_error=str(e)[:100])
            continue

    if new_dates:
        update_status("processing", 1, "MP3å¤‰æ›å®Œäº†", files_total=len(new_files), files_completed=len(new_files))
        notify(
            "Voice Memo",
            f"Phase 1å®Œäº†: {len(new_files)}ä»¶ã‚’å¤‰æ›æ¸ˆã¿ã€‚USBã¯å®‰å…¨ã«å–ã‚Šå¤–ã›ã¾ã™",
            sound="Glass",
        )

    return new_dates


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Phase 2: Transcribe from Google Drive MP3
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def get_audio_duration(file_path: Path) -> float:
    """Get duration in seconds using ffprobe."""
    cmd = [
        FFPROBE_PATH,
        "-v", "error",
        "-show_entries", "format=duration",
        "-of", "csv=p=0",
        str(file_path),
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
    if result.returncode != 0:
        raise RuntimeError(f"ffprobe failed: {result.stderr[-500:]}")
    return float(result.stdout.strip())


# Known Whisper hallucination phrases (from YouTube training data leakage etc.)
HALLUCINATION_PHRASES = {
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ",
    "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ãŠé¡˜ã„ã—ã¾ã™",
    "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™",
    "ã„ã„ã­ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„",
    "ã‚°ãƒƒãƒ‰ãƒœã‚¿ãƒ³ãŠé¡˜ã„ã—ã¾ã™",
    "ã”æ¸…è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ",
    "å­—å¹•ã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™",
    "ã“ã®å‹•ç”»ãŒæ°—ã«å…¥ã£ãŸã‚‰",
    "æ¬¡å›ã‚‚ãŠæ¥½ã—ã¿ã«",
    "Thanks for watching",
    "Please subscribe",
    "Like and subscribe",
}

# Common short hallucination tokens (nonsense fragments Whisper generates)
HALLUCINATION_TOKENS = {"arte", "artearte", "arteartearte"}


def is_hallucination(text: str) -> bool:
    """Detect hallucinated/repetitive segments from Whisper."""
    t = text.strip()
    if not t:
        return True

    # Too short to be meaningful (single char or just punctuation/filler)
    if len(t) <= 2:
        return True

    # Known hallucination phrases (YouTube training data leakage)
    if t in HALLUCINATION_PHRASES:
        return True

    # Short nonsense tokens Whisper hallucinates (e.g. "arte", "artearte")
    # Catch standalone, embedded ("ã£artearte"), or mixed ("ä»Šå›artearte")
    if re.search(r"(arte){1,}", t):
        return True

    # Whisper hallucination: "oud" / "oudoud..." repetitions
    if re.search(r"(oud){1,}", t) and len(re.sub(r"(oud)+", "", t).strip()) < 5:
        return True

    # Whisper hallucination: "amb" repeated ("amb amb amb...")
    if re.search(r"(amb[\s]*){2,}", t):
        return True

    # Whisper hallucination: "Honor" repeated
    if re.search(r"(Honor[\s]*){2,}", t):
        return True

    # Whisper hallucination: "SCO" repeated
    if re.search(r"(SCO[\s]*){2,}", t):
        return True

    # Detect repeated characters like "ã‚ã‚ã‚ã‚", "ã†ã†ã†ã†", "ãˆãˆãˆ"
    if re.match(r"^(.)\1{2,}$", t):
        return True

    # Detect patterns like "ã‚ã‚ã‚ã‚ã‚ã‚ ã¯ãŸ" (repeated chars + short word)
    if re.match(r"^(.)\1{3,}(\s+.{0,4})?$", t):
        return True

    # Detect short phrase repetition (2-6 chars repeated 3+ times)
    # Catches: "è³ªå•ã¯è³ªå•ã¯è³ªå•ã¯...", "ãŠåº—ã®ãŠåº—ã®ãŠåº—ã®...", "æ›¸ã‘ã¦æ›¸ã‘ã¦æ›¸ã‘ã¦..."
    if re.search(r"(.{2,6})\1{2,}", t):
        # Only flag if the repeated part dominates the text (>50%)
        m = re.search(r"(.{2,6})\1{2,}", t)
        if m and len(m.group(0)) > len(t) * 0.5:
            return True

    # Detect long strings with >60% same character (e.g. "ãƒ¨ãƒ¼ãƒŠãƒ¨ãƒ¨ãƒ¨ãƒ¨ãƒ¨ãƒ¨ãƒ¨...")
    if len(t) > 10:
        from collections import Counter
        char_counts = Counter(t.replace(" ", ""))
        if char_counts and char_counts.most_common(1)[0][1] / len(t.replace(" ", "")) > 0.6:
            return True

    return False


def _normalize_text(text: str) -> str:
    """Normalize text for comparison (strip punctuation variants)."""
    # Remove trailing punctuation differences: "ãŠã‚„ã™ã¿ãªã•ã„" vs "ãŠã‚„ã™ã¿ãªã•ã„ã€‚"
    return re.sub(r"[ã€‚ã€ï¼ï¼Ÿ!?.,\s]+$", "", text.strip())


def filter_hallucinated_segments(segments: list[dict]) -> list[dict]:
    """Remove hallucinated/repetitive segments from transcription output."""
    if not segments:
        return segments

    filtered = []
    # Track recent texts (sliding window) to catch non-consecutive repetition
    recent_texts: list[str] = []  # normalized texts of last N segments
    WINDOW_SIZE = 10
    MAX_REPEATS_IN_WINDOW = 2  # Allow max 2 same texts in a window of 10

    for seg in segments:
        text = seg["text"].strip()

        # Skip individually hallucinated segments
        if is_hallucination(text):
            continue

        # Check repetition within sliding window
        norm = _normalize_text(text)
        occurrences = recent_texts.count(norm)
        if occurrences >= MAX_REPEATS_IN_WINDOW:
            continue  # Too many repeats in recent window, skip

        recent_texts.append(norm)
        if len(recent_texts) > WINDOW_SIZE:
            recent_texts.pop(0)

        filtered.append(seg)

    before = len(segments)
    after = len(filtered)
    if before != after:
        logger.info(
            f"  Hallucination filter: {before} â†’ {after} segments "
            f"({before - after} removed)"
        )

    return filtered


def _run_whisper(audio_path: str) -> dict:
    """Run mlx-whisper transcription on an audio file path."""
    return mlx_whisper.transcribe(
        audio_path,
        path_or_hf_repo=WHISPER_MODEL_REPO,
        language="ja",
        word_timestamps=True,
        condition_on_previous_text=False,   # Prevent hallucination cascading
        compression_ratio_threshold=2.4,     # Reject overly repetitive output
        no_speech_threshold=0.6,             # Detect non-speech segments
        # NOTE: hallucination_silence_threshold intentionally omitted (22x slower)
        # Post-processing filter handles hallucination cleanup instead
    )


def _find_local_mp3(mp3_path: Path) -> Path | None:
    """Check if a local staging copy exists for this MP3."""
    staging_path = STAGING_DIR / mp3_path.name
    if staging_path.exists() and staging_path.stat().st_size > 1024:
        return staging_path
    return None


def transcribe_local(mp3_path: Path) -> dict:
    """Transcribe audio using mlx-whisper locally (Apple Silicon GPU).

    Prefers local staging copy over Google Drive to avoid FUSE deadlock.
    Falls back to copying from Google Drive with retries if no staging copy.
    """
    logger.info(f"  Transcribing locally: {mp3_path.name}")
    start_time = time.time()

    # Check if file is on Google Drive (FUSE mount) â€” may need local copy
    is_cloud = "CloudStorage" in str(mp3_path) or "GoogleDrive" in str(mp3_path)

    if is_cloud:
        # Prefer local staging copy (written in Phase 1, no FUSE issues)
        local_path = _find_local_mp3(mp3_path)
        if local_path:
            logger.info(f"  Using staging copy: {local_path}")
            result = _run_whisper(str(local_path))
        else:
            # No staging copy â€” fall back to copying from Google Drive with retries
            tmp_dir = Path(tempfile.mkdtemp(prefix="voicememo_"))
            tmp_path = tmp_dir / mp3_path.name
            try:
                max_cp_retries = 5
                for cp_attempt in range(1, max_cp_retries + 1):
                    logger.info(f"  Copying from Google Drive to local temp (attempt {cp_attempt}/{max_cp_retries})...")
                    try:
                        with open(mp3_path, "rb") as src, open(tmp_path, "wb") as dst:
                            while True:
                                chunk = src.read(1024 * 1024)
                                if not chunk:
                                    break
                                dst.write(chunk)
                        break  # Success
                    except OSError as e:
                        logger.warning(f"  Copy failed: {e}")
                        tmp_path.unlink(missing_ok=True)
                        if cp_attempt < max_cp_retries:
                            delay = 30 * cp_attempt  # 30s, 60s, 90s, 120s
                            logger.info(f"  Waiting {delay}s before retry...")
                            time.sleep(delay)
                        else:
                            raise RuntimeError(
                                f"Copy failed after {max_cp_retries} attempts: {e}"
                            )
                logger.info(f"  Transcribing from: {tmp_path}")
                result = _run_whisper(str(tmp_path))
            finally:
                tmp_path.unlink(missing_ok=True)
                tmp_dir.rmdir()
                logger.info(f"  Cleaned up temp copy")
    else:
        result = _run_whisper(str(mp3_path))

    elapsed = time.time() - start_time
    duration = result.get("segments", [{}])[-1].get("end", 0) if result.get("segments") else 0

    # If segments didn't give us duration, use ffprobe
    if duration == 0:
        try:
            duration = get_audio_duration(mp3_path)
        except Exception:
            pass

    segments = [
        {
            "start": seg["start"],
            "end": seg["end"],
            "text": seg["text"],
        }
        for seg in result.get("segments", [])
        if seg.get("text", "").strip()
    ]

    # Post-processing: filter out hallucinated/repetitive segments
    segments = filter_hallucinated_segments(segments)

    # Rebuild clean text from filtered segments
    text = " ".join(seg["text"].strip() for seg in segments)

    logger.info(
        f"  Transcribed: {len(segments)} segments, "
        f"{duration:.0f}s audio in {elapsed:.1f}s"
    )

    return {
        "text": text,
        "segments": segments,
        "duration": duration,
    }


def discover_untranscribed_mp3s(manifest: dict) -> list[dict]:
    """Find MP3 files in Google Drive that haven't been transcribed yet."""
    untranscribed = []

    for wav_name, copy_entry in manifest["copied"].items():
        mp3_name = copy_entry["mp3_name"]

        # Already transcribed?
        if mp3_name in manifest["transcribed"]:
            continue

        # Find the MP3 file
        date = copy_entry["date"]
        mp3_path = MP3_BASE_DIR / date / mp3_name

        # Also check flat directory (legacy from v1)
        if not mp3_path.exists():
            mp3_path = MP3_BASE_DIR / mp3_name

        if not mp3_path.exists():
            logger.warning(f"  MP3 not found: {mp3_name} (skipping)")
            continue

        untranscribed.append(
            {
                "mp3_path": mp3_path,
                "mp3_name": mp3_name,
                "date": copy_entry["date"],
                "time": copy_entry["time"],
                "time_full": copy_entry.get("time_full", copy_entry["time"] + ":00"),
            }
        )

    return untranscribed


def phase2_transcribe(manifest: dict) -> set[str]:
    """
    Phase 2: Transcribe untranscribed MP3 files from Google Drive using mlx-whisper.
    Returns set of dates that had new transcriptions.
    """
    untranscribed = discover_untranscribed_mp3s(manifest)

    if not untranscribed:
        logger.info("Phase 2: No untranscribed MP3 files")
        return set()

    logger.info(f"Phase 2: {len(untranscribed)} file(s) to transcribe")
    notify("Voice Memo", f"Phase 2: {len(untranscribed)}ä»¶ã®æ–‡å­—èµ·ã“ã—é–‹å§‹...")
    update_status("processing", 2, "æ–‡å­—èµ·ã“ã—ä¸­", files_total=len(untranscribed))
    new_dates = set()
    success_count = 0
    fail_count = 0

    # Count expected files per date for partial-failure detection
    date_file_counts: dict[str, int] = {}
    for mp3_info in untranscribed:
        d = mp3_info["date"]
        date_file_counts[d] = date_file_counts.get(d, 0) + 1

    for i, mp3_info in enumerate(untranscribed, 1):
        mp3_name = mp3_info["mp3_name"]
        logger.info(f"Processing: {mp3_name}")
        notify("Voice Memo", f"æ–‡å­—èµ·ã“ã—ä¸­ ({i}/{len(untranscribed)}): {mp3_info['time']}")
        update_status("processing", 2, "æ–‡å­—èµ·ã“ã—ä¸­", mp3_name, len(untranscribed), i - 1)

        try:
            transcript = transcribe_local(mp3_info["mp3_path"])

            manifest["transcribed"][mp3_name] = {
                "transcribed_at": datetime.now().isoformat(),
                "duration_seconds": transcript["duration"],
                "date": mp3_info["date"],
                "time": mp3_info["time"],
                "time_full": mp3_info["time_full"],
                "transcript_text": transcript["text"],
                "segments": transcript["segments"],
            }
            save_manifest(manifest)
            new_dates.add(mp3_info["date"])
            success_count += 1

            # Clean up staging copy after successful transcription
            staging_path = STAGING_DIR / mp3_name
            if staging_path.exists():
                staging_path.unlink()
                logger.info(f"  Cleaned up staging file: {mp3_name}")

        except Exception as e:
            logger.error(f"  FAILED transcribing {mp3_name}: {e}", exc_info=True)
            update_status("processing", 2, "æ–‡å­—èµ·ã“ã—ä¸­", mp3_name, len(untranscribed), i - 1, last_error=str(e)[:100])
            fail_count += 1
            continue

    if fail_count > 0:
        logger.warning(f"Phase 2 completed with {fail_count} failures out of {len(untranscribed)} files")
        notify("Voice Memo", f"âš  æ–‡å­—èµ·ã“ã—: {success_count}æˆåŠŸ / {fail_count}å¤±æ•—ï¼ˆæ¬¡å›è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼‰")

    return new_dates


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Phase 3: GPT-4o summary + Markdown
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def retry_with_backoff(func, max_retries=3, base_delay=5):
    for attempt in range(max_retries):
        try:
            return func()
        except (openai.RateLimitError, openai.APITimeoutError) as e:
            if attempt == max_retries - 1:
                raise
            delay = base_delay * (2**attempt)
            logger.warning(
                f"API error ({type(e).__name__}), retrying in {delay}s "
                f"(attempt {attempt + 1}/{max_retries})"
            )
            time.sleep(delay)
        except openai.APIError as e:
            if attempt == max_retries - 1:
                raise
            delay = base_delay * (2**attempt)
            logger.warning(f"API error ({e}), retrying in {delay}s")
            time.sleep(delay)
    raise RuntimeError(f"Failed after {max_retries} retries")


def _build_transcript_block(recordings: list[dict]) -> str:
    """Build a transcript text block from a list of recordings."""
    block = ""
    for rec in recordings:
        block += (
            f"\n--- Recording at {rec['time']} "
            f"({rec['duration_min']:.0f} min) ---\n"
        )
        clean_segs = filter_hallucinated_segments(rec["segments"])
        clean_text = " ".join(s["text"].strip() for s in clean_segs if s["text"].strip())
        block += (clean_text or rec["transcript_text"]) + "\n"
    return block


def _call_summary_api(client: openai.OpenAI, prompt: str) -> dict:
    """Call GPT-4o with a summary prompt and return parsed JSON."""
    response = client.chat.completions.create(
        model=GPT_MODEL,
        messages=[
            {
                "role": "system",
                "content": (
                    "You are a helpful assistant that summarizes voice memos "
                    "in Japanese. Always respond with valid JSON."
                ),
            },
            {"role": "user", "content": prompt},
        ],
        response_format={"type": "json_object"},
        temperature=0.3,
        max_tokens=2000,
    )
    return json.loads(response.choices[0].message.content)


MAX_CHARS_PER_CHUNK = 20000  # ~7,000 tokens â€” safe for 30k TPM limit


def summarize_transcripts(
    client: openai.OpenAI, date: str, recordings: list[dict],
    profile: dict | None = None
) -> dict:
    """Call GPT-4o to generate summary and highlights.

    If the transcript is too long for a single API call, it is split into
    chunks, each chunk is summarized individually, and the partial summaries
    are merged in a final API call.
    """
    profile = profile or {}
    profile_ctx = _build_profile_context(profile)
    profile_section = f"""
ã€æŠ•ç¨¿è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã€‘
{profile_ctx}
""" if profile_ctx else ""

    # SNS post instructions (shared between single / merge prompts)
    _sns_instructions = f"""{profile_section}
ä»¥ä¸‹ã®è¦³ç‚¹ã§ã€SNSã«æŠ•ç¨¿ã§ãã‚‹ãƒã‚¹ãƒˆæ¡ˆã‚’5ã€œ10ä»¶ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ãã‚Œãã‚Œç•°ãªã‚‹è§’åº¦ãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§:
- ã€æ°—ã¥ãå‹ã€‘: ä»Šæ—¥å­¦ã‚“ã ã“ã¨ãƒ»æ°—ã¥ã„ãŸã“ã¨ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«
- ã€å•ã„ã‹ã‘å‹ã€‘: èª­è€…ã«è€ƒãˆã•ã›ã‚‹å•ã„ã‚’ç«‹ã¦ã‚‹
- ã€æ„è¦‹å‹ã€‘: è‡ªåˆ†ã®æ„è¦‹ãƒ»ç«‹å ´ã‚’æ˜ç¢ºã«ã—ãŸãƒã‚¹ãƒˆ
- ã€ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å‹ã€‘: ä»Šæ—¥ã®å‡ºæ¥äº‹ã‚’çŸ­ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¨ã—ã¦
- ã€å¼•ç”¨å‹ã€‘: ä¼šè©±ã®ä¸­ã®å°è±¡çš„ãªè¨€è‘‰ã‚’è»¸ã«
- ã€æ´å¯Ÿå‹ã€‘: æŠ½è±¡åº¦ã‚’ä¸Šã’ãŸæ·±ã„è€ƒå¯Ÿ
- ã€Xã‚¹ãƒ¬ãƒƒãƒ‰å‹ã€‘: Hookâ†’æœ¬è«–â†’CTAã®æ§‹æˆã§å®Œçµã™ã‚‹æ•°ãƒ„ã‚¤ãƒ¼ãƒˆåˆ†ï¼ˆJSONå†…ã§ã¯1ã¤ã®æ–‡å­—åˆ—ã¨ã—ã¦æ”¹è¡Œç­‰ã§åŒºåˆ‡ã£ã¦è¡¨ç¾ï¼‰
- ã€Threadsç”¨ãƒ­ãƒ³ã‚°ã€‘: 500æ–‡å­—ç¨‹åº¦ã§æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã”ã¨æ›¸ãé•·æ–‡ãƒã‚¹ãƒˆ

ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯Xï¼ˆå˜ç™ºã¯140æ–‡å­—ä»¥å†…ï¼‰ã€Xã‚¹ãƒ¬ãƒƒãƒ‰ã€Threadsï¼ˆ500æ–‡å­—ä»¥å†…ï¼‰ã®ã„ãšã‚Œã‹ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚

ã€SNSãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ãƒ»ãƒ«ãƒ¼ãƒ«ã®å³å®ˆã€‘
1. å®Œå…¨ãªäººé–“ã‚‰ã—ã•ï¼ˆAIã£ã½ã•ã‚¼ãƒ­ï¼‰: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã¨éå»ã®æŠ•ç¨¿ä¾‹ã‹ã‚‰ã€ãƒˆãƒ¼ãƒ³ãƒ»èªå°¾ãƒ»æ”¹è¡Œã®ã‚¯ã‚»ãƒ»ãƒ¦ãƒ¼ãƒ¢ã‚¢ã®å…¥ã‚Œæ–¹ã‚’å®Œå…¨ã«æ¨¡å€£ã—ã¦ãã ã•ã„ã€‚
2. Xå‘ã‘ã®æœ€é©åŒ–: æœ€åˆã®1æ–‡ã«å¼·åŠ›ãªHookï¼ˆå•ã„ã‹ã‘ãƒ»å…±æ„Ÿãƒ»æ„å¤–æ€§ï¼‰ã‚’å…¥ã‚Œã€çµµæ–‡å­—ã¯å…¨ä½“ã§1ã€œ3å€‹ä»¥å†…ã«æŠ‘ãˆã¦ãã ã•ã„ã€‚
3. ã‚¹ãƒ‘ãƒ è¡¨ç¾ã®ç¦æ­¢: ã€Œä»Šã™ãã€ã€Œæ¿€ã‚¢ãƒ„ã€ã€Œäººç”Ÿå¤‰ã‚ã‚‹ã€ã€Œã€œã—ã¦ã¿ãŸçµæœã€ãªã©ã®éå‰°ãªç…½ã‚Šæ–‡å¥ã¯çµ¶å¯¾ã«é¿ã‘ã¦ãã ã•ã„ã€‚
4. è‡ªç„¶ãªæ—¥æœ¬èª: ç¿»è¨³èª¿ã‚’é¿ã‘ã€è¦ªã—ã¿ã‚„ã™ã•ã¨å°‘ã—ã®æ¯’ã£æ°—ã‚„ã‚¦ã‚£ãƒƒãƒˆã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‚"""

    transcript_block = _build_transcript_block(recordings)

    # If short enough, summarize in one shot
    if len(transcript_block) <= MAX_CHARS_PER_CHUNK:
        prompt = f"""ä»¥ä¸‹ã¯{date}ã®ãƒœã‚¤ã‚¹ãƒ¡ãƒ¢ã®æ–‡å­—èµ·ã“ã—ã§ã™ã€‚
ã“ã‚Œã‚’åˆ†æã—ã¦ã€è©³ç´°ãªæ—¥å ±ã¨ã—ã¦æ•´ç†ã—ã¦ãã ã•ã„ã€‚

{transcript_block}

ä»¥ä¸‹ã®å½¢å¼ã§JSONå‡ºåŠ›ã—ã¦ãã ã•ã„:
{{
  "summary": "ã“ã®æ—¥1æ—¥ã®æ´»å‹•ã®æµã‚Œï¼ˆ5ã€œ8æ–‡ã€æ™‚ç³»åˆ—ã§ã€‚ä½•ã‚’ã—ã¦ã€ã©ã†å‹•ã„ã¦ã€ã©ã‚“ãªã“ã¨ã‚’è€ƒãˆã¦ã„ãŸã‹ã‚’å…·ä½“çš„ã«ï¼‰",
  "time_breakdown": [
    {{
      "time": "09:00ã€œ11:30",
      "duration_min": 150,
      "category": "ã‚«ãƒ†ã‚´ãƒªï¼ˆä¾‹: ä»•äº‹ãƒ»æ‰“åˆã›ãƒ»ç§»å‹•ãƒ»é£Ÿäº‹ãƒ»ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ»å­¦ç¿’ãªã©ï¼‰",
      "activity": "æ´»å‹•å†…å®¹ï¼ˆç°¡æ½”ã«ï¼‰",
      "details": "å…·ä½“çš„ãªå†…å®¹ãƒ»è©±é¡Œãƒ»æˆæœãªã©ï¼ˆ3ã€œ5æ–‡ã€‚ä½•ã‚’è©±ã—ãŸã‹ã€ã©ã‚“ãªæ„æ€æ±ºå®šãŒã‚ã£ãŸã‹ã€ã©ã‚“ãªçµæœã‚„æ°—ã¥ããŒç”Ÿã¾ã‚ŒãŸã‹ã¾ã§è©³ã—ãæ›¸ãï¼‰"
    }}
  ],
  "deep_conversations": [
    {{
      "topic": "è©±é¡Œã®ã‚¿ã‚¤ãƒˆãƒ«",
      "insight": "ã“ã®ä¼šè©±ãƒ»è€ƒãˆã®ã‚¨ãƒƒã‚»ãƒ³ã‚¹ï¼ˆ2ã€œ4æ–‡ï¼‰ã€‚æŠ½è±¡åº¦ãŒé«˜ã„ã€è€ƒãˆãŒæ·±ã„ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦–ç‚¹ãªã©ä¾¡å€¤ã‚ã‚‹ã‚‚ã®ã€‚",
      "quote": "ä¼šè©±ã‹ã‚‰å°è±¡çš„ãƒ»æœ¬è³ªçš„ãªã²ã¨ã“ã¨ã‚’åŸæ–‡ã«è¿‘ã„å½¢ã§æŠœç²‹ï¼ˆã‚ã‚Œã°ï¼‰"
    }}
  ],
  "action_items": ["ä»Šå¾Œã‚„ã‚‹ã¹ãã“ã¨", "æ±ºå®šäº‹é …", "ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—"],
  "x_threads_posts": [
    {{
      "platform": "X ã¾ãŸã¯ Xã‚¹ãƒ¬ãƒƒãƒ‰ ã¾ãŸã¯ Threads",
      "type": "æ°—ã¥ãå‹ãƒ»å•ã„ã‹ã‘å‹ãƒ»æ„è¦‹å‹ãƒ»ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å‹ãƒ»å¼•ç”¨å‹ãƒ»æ´å¯Ÿå‹ãƒ»Xã‚¹ãƒ¬ãƒƒãƒ‰å‹ãƒ»Threadsç”¨ãƒ­ãƒ³ã‚° ã®ã„ãšã‚Œã‹",
      "content": "ãƒã‚¹ãƒˆæ–‡ï¼ˆX=140æ–‡å­—ä»¥å†… / Threads=500æ–‡å­—ä»¥å†… / Xã‚¹ãƒ¬ãƒƒãƒ‰=é©å®œæ”¹è¡Œï¼‰"
    }}
  ]
}}

ãƒ«ãƒ¼ãƒ«:
- summaryã¯ã“ã®æ—¥1æ—¥ã®æµã‚Œã‚’æ™‚ç³»åˆ—ã§å…·ä½“çš„ã«ã¾ã¨ã‚ã¦ãã ã•ã„
- time_breakdownã¯éŒ²éŸ³æ™‚åˆ»ã‚’ã‚‚ã¨ã«æ™‚é–“å¸¯ã”ã¨ã®æ´»å‹•ã‚’åˆ—æŒ™ã€‚ç§»å‹•ä¸­ãƒ»é›‘è«‡ãƒ»ç’°å¢ƒéŸ³ã®ã¿ã®æ™‚é–“å¸¯ã¯å«ã‚ãªãã¦OKã§ã™
- deep_conversationsã¯ã€ŒæŠ½è±¡åº¦ãŒé«˜ã„ã€ã€Œæœ¬è³ªçš„ã€ã€Œãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦–ç‚¹ãŒã‚ã‚‹ã€ã€Œå­¦ã³ã‚„æ°—ã¥ããŒã‚ã‚‹ã€ä¼šè©±ãƒ»æ€è€ƒã‚’2ã€œ5ä»¶æŠœç²‹
- x_threads_postsã¯ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦5ã€œ10ä»¶ç”Ÿæˆã€‚è§’åº¦ãƒ»ã‚¿ã‚¤ãƒ—ãŒè¢«ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
- å…¨ã¦æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„

{_sns_instructions}"""
        return _call_summary_api(client, prompt)

    # --- Chunked summarization for long transcripts ---
    logger.info(
        f"  Transcript too long ({len(transcript_block)} chars), "
        f"splitting into chunks of {MAX_CHARS_PER_CHUNK} chars"
    )

    # Split recordings into chunks that fit under the limit
    chunks: list[list[dict]] = []
    current_chunk: list[dict] = []
    current_len = 0

    for rec in recordings:
        rec_block = _build_transcript_block([rec])
        rec_len = len(rec_block)

        if current_len + rec_len > MAX_CHARS_PER_CHUNK and current_chunk:
            chunks.append(current_chunk)
            current_chunk = []
            current_len = 0

        current_chunk.append(rec)
        current_len += rec_len

    if current_chunk:
        chunks.append(current_chunk)

    logger.info(f"  Split into {len(chunks)} chunks")

    # Summarize each chunk
    partial_summaries = []
    for ci, chunk_recs in enumerate(chunks, 1):
        chunk_block = _build_transcript_block(chunk_recs)
        time_range = f"{chunk_recs[0]['time']}ã€œ{chunk_recs[-1]['time']}"
        logger.info(f"  Summarizing chunk {ci}/{len(chunks)} ({time_range})")

        chunk_prompt = f"""ä»¥ä¸‹ã¯{date}ã®ãƒœã‚¤ã‚¹ãƒ¡ãƒ¢ã®ä¸€éƒ¨ï¼ˆ{time_range}ï¼‰ã®æ–‡å­—èµ·ã“ã—ã§ã™ã€‚
ã“ã®æ™‚é–“å¸¯ã«ä½•ã‚’ã—ã¦ã„ãŸã‹ã€ã©ã‚“ãªä¼šè©±ã‚„è€ƒãˆãŒã‚ã£ãŸã‹ã‚’è©³ã—ãæŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

{chunk_block}

ä»¥ä¸‹ã®å½¢å¼ã§JSONå‡ºåŠ›ã—ã¦ãã ã•ã„:
{{
  "summary": "ã“ã®æ™‚é–“å¸¯ã®æ´»å‹•ãƒ»æ€è€ƒã®è¦ç´„ï¼ˆ3ã€œ5æ–‡ï¼‰",
  "time_breakdown": [
    {{
      "time": "é–‹å§‹ã€œçµ‚äº†",
      "duration_min": 60,
      "category": "ã‚«ãƒ†ã‚´ãƒª",
      "activity": "æ´»å‹•å†…å®¹",
      "details": "å…·ä½“çš„ãªå†…å®¹ï¼ˆ3ã€œ5æ–‡ã€‚ä½•ã‚’è©±ã—ãŸã‹ã€ã©ã‚“ãªæ„æ€æ±ºå®šãŒã‚ã£ãŸã‹ã€ã©ã‚“ãªçµæœã‚„æ°—ã¥ããŒç”Ÿã¾ã‚ŒãŸã‹ã¾ã§è©³ã—ãæ›¸ãï¼‰"
    }}
  ],
  "deep_conversations": [
    {{
      "topic": "è©±é¡Œ",
      "insight": "ã‚¨ãƒƒã‚»ãƒ³ã‚¹ï¼ˆ2ã€œ3æ–‡ï¼‰",
      "quote": "å°è±¡çš„ãªä¸€è¨€ï¼ˆã‚ã‚Œã°ï¼‰"
    }}
  ],
  "action_items": ["TODO"]
}}

ãƒ«ãƒ¼ãƒ«:
- time_breakdownã¯éŒ²éŸ³æ™‚åˆ»ã‚’ã‚‚ã¨ã«æ´»å‹•ã‚’åˆ—æŒ™
- deep_conversationsã¯æŠ½è±¡åº¦ãŒé«˜ã„ãƒ»æœ¬è³ªçš„ãƒ»ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªä¼šè©±ã‚„æ€è€ƒã‚’æŠ½å‡º
- action_itemsãŒãªã‘ã‚Œã°ç©ºé…åˆ—
- å…¨ã¦æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„"""

        partial = retry_with_backoff(
            lambda p=chunk_prompt: _call_summary_api(client, p)
        )
        partial_summaries.append(partial)
        time.sleep(2)  # Avoid TPM burst

    # Merge partial summaries into final summary
    logger.info("  Merging partial summaries...")
    merge_input = ""
    for ci, ps in enumerate(partial_summaries, 1):
        merge_input += f"\n--- ãƒ‘ãƒ¼ãƒˆ{ci} ---\n"
        merge_input += f"è¦ç´„: {ps.get('summary', '')}\n"
        if ps.get("time_breakdown"):
            merge_input += "æ´»å‹•:\n"
            for act in ps["time_breakdown"]:
                merge_input += (
                    f"- {act.get('time', '?')} [{act.get('category', '')}]: {act.get('activity', '')} "
                    f"({act.get('duration_min', '?')}åˆ†) â€” {act.get('details', '')}\n"
                )
        # Legacy support
        if ps.get("activities"):
            merge_input += "æ´»å‹•(æ—§å½¢å¼):\n"
            for act in ps["activities"]:
                merge_input += (
                    f"- {act.get('time', '?')}: {act.get('activity', '')} "
                    f"({act.get('duration_min', '?')}åˆ†) â€” {act.get('details', '')}\n"
                )
        if ps.get("deep_conversations"):
            merge_input += "æ·±ã„ä¼šè©±ãƒ»è€ƒå¯Ÿ:\n"
            for dc in ps["deep_conversations"]:
                merge_input += f"- [{dc.get('topic','')}] {dc.get('insight','')}\n"
                if dc.get("quote"):
                    merge_input += f"  å¼•ç”¨: ã€Œ{dc.get('quote','')}ã€\n"
        if ps.get("action_items"):
            merge_input += "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ :\n"
            for ai in ps["action_items"]:
                merge_input += f"- {ai}\n"

    merge_prompt = f"""ä»¥ä¸‹ã¯{date}ã®ãƒœã‚¤ã‚¹ãƒ¡ãƒ¢ã‚’è¤‡æ•°ãƒ‘ãƒ¼ãƒˆã«åˆ†ã‘ã¦åˆ†æã—ãŸçµæœã§ã™ã€‚
ã“ã‚Œã‚‰ã‚’çµ±åˆã—ã¦ã€1æ—¥å…¨ä½“ã®è©³ç´°ãªæ—¥å ±ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

{merge_input}

ä»¥ä¸‹ã®å½¢å¼ã§JSONå‡ºåŠ›ã—ã¦ãã ã•ã„:
{{
  "summary": "ã“ã®æ—¥1æ—¥ã®æ´»å‹•ã®æµã‚Œï¼ˆ5ã€œ8æ–‡ï¼‰",
  "time_breakdown": [
    {{
      "time": "é–‹å§‹ã€œçµ‚äº†",
      "duration_min": 60,
      "category": "ã‚«ãƒ†ã‚´ãƒª",
      "activity": "æ´»å‹•å†…å®¹",
      "details": "è©³ç´°ï¼ˆ2ã€œ3æ–‡ï¼‰"
    }}
  ],
  "deep_conversations": [
    {{
      "topic": "è©±é¡Œ",
      "insight": "ã‚¨ãƒƒã‚»ãƒ³ã‚¹ï¼ˆ2ã€œ4æ–‡ï¼‰",
      "quote": "å°è±¡çš„ãªä¸€è¨€ï¼ˆã‚ã‚Œã°ï¼‰"
    }}
  ],
  "action_items": ["TODO1", "TODO2"],
  "x_threads_posts": [
    {{
      "platform": "X ã¾ãŸã¯ Xã‚¹ãƒ¬ãƒƒãƒ‰ ã¾ãŸã¯ Threads",
      "type": "æ°—ã¥ãå‹ãƒ»å•ã„ã‹ã‘å‹ãƒ»æ„è¦‹å‹ãƒ»ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å‹ãƒ»å¼•ç”¨å‹ãƒ»æ´å¯Ÿå‹ãƒ»Xã‚¹ãƒ¬ãƒƒãƒ‰å‹ãƒ»Threadsç”¨ãƒ­ãƒ³ã‚° ã®ã„ãšã‚Œã‹",
      "content": "ãƒã‚¹ãƒˆæ–‡ï¼ˆX=140æ–‡å­—ä»¥å†… / Threads=500æ–‡å­—ä»¥å†… / Xã‚¹ãƒ¬ãƒƒãƒ‰=é©å®œæ”¹è¡Œï¼‰"
    }}
  ]
}}

ãƒ«ãƒ¼ãƒ«:
- summaryã¯1æ—¥ã®æµã‚Œã‚’æ™‚ç³»åˆ—ã§å…·ä½“çš„ã«ã¾ã¨ã‚ã¦ãã ã•ã„
- time_breakdownã¯å…¨ãƒ‘ãƒ¼ãƒˆã®æ´»å‹•ã‚’çµ±åˆã—ã¦æ™‚ç³»åˆ—ã§ä¸¦ã¹ã€é‡è¤‡ã‚’æ’é™¤ã—ã¦ãã ã•ã„
- deep_conversationsã¯å…¨ãƒ‘ãƒ¼ãƒˆã‹ã‚‰æœ¬è³ªçš„ãƒ»ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ»å­¦ã³ã®ã‚ã‚‹ä¼šè©±ã‚’2ã€œ5ä»¶é¸ã‚“ã§ãã ã•ã„
- x_threads_postsã¯ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦5ã€œ10ä»¶ç”Ÿæˆã—ã¦ãã ã•ã„
- å…¨ã¦æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„

{_sns_instructions}"""

    return _call_summary_api(client, merge_prompt)


def format_timestamp(seconds: float) -> str:
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    if h > 0:
        return f"{h}:{m:02d}:{s:02d}"
    return f"{m:02d}:{s:02d}"


def _format_duration(minutes: int) -> str:
    """Format duration in minutes to a human-readable string."""
    if minutes >= 60:
        h = minutes // 60
        m = minutes % 60
        return f"ç´„{h}æ™‚é–“{m}åˆ†" if m else f"ç´„{h}æ™‚é–“"
    return f"ç´„{minutes}åˆ†"


def generate_markdown(
    date: str, recordings: list[dict], summary_data: dict
) -> str:
    lines = []
    lines.append(f"# ğŸ““ æ—¥å ± â€” {date}")
    lines.append("")

    # â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    lines.append("## ğŸ—“ ã‚µãƒãƒªãƒ¼")
    lines.append("")
    lines.append(summary_data.get("summary", "(è¦ç´„ãªã—)"))
    lines.append("")

    # â”€â”€ Time breakdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    time_breakdown = summary_data.get("time_breakdown", []) or summary_data.get("activities", [])
    if time_breakdown:
        lines.append("## â± æ™‚é–“ã®ä½¿ã„æ–¹")
        lines.append("")
        for act in time_breakdown:
            time_str = act.get("time", "â€”")
            dur = act.get("duration_min", 0)
            dur_str = _format_duration(dur) if dur else "â€”"
            category = act.get("category", "")
            activity = act.get("activity", "")
            details = act.get("details", "")
            # Card-style: subheading with time + category badge, then details paragraph
            badge = f" `{category}`" if category else ""
            lines.append(f"### ğŸ• {time_str}  ({dur_str}){badge}")
            lines.append(f"**{activity}**")
            lines.append("")
            if details:
                lines.append(details)
            lines.append("")

    # â”€â”€ Deep conversations / Highlights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    deep_convs = summary_data.get("deep_conversations", [])
    if deep_convs:
        lines.append("## ğŸ’¡ æ·±ã„ä¼šè©±ãƒ»æ°—ã¥ã")
        lines.append("")
        for dc in deep_convs:
            topic = dc.get("topic", "")
            insight = dc.get("insight", "")
            quote = dc.get("quote", "")
            lines.append(f"### {topic}")
            lines.append(insight)
            if quote:
                lines.append("")
                lines.append(f"> ã€Œ{quote}ã€")
            lines.append("")

    # â”€â”€ Backward compat: old highlights field â”€â”€â”€â”€
    highlights = summary_data.get("highlights", [])
    if highlights and not deep_convs:
        lines.append("## ğŸ’¡ ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
        lines.append("")
        for h in highlights:
            lines.append(f"- {h}")
        lines.append("")

    # â”€â”€ Action items â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    action_items = summary_data.get("action_items", [])
    if action_items:
        lines.append("## âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ")
        lines.append("")
        for item in action_items:
            lines.append(f"- [ ] {item}")
        lines.append("")

    # â”€â”€ SNS Post Suggestions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    posts = summary_data.get("x_threads_posts", [])
    if posts:
        lines.append("## ğŸ“£ æƒ…å ±ç™ºä¿¡ãƒ»æŠ•ç¨¿æ¡ˆ")
        lines.append("")
        for i, post in enumerate(posts, 1):
            platform = post.get("platform", "SNS")
            post_type = post.get("type", "")
            content = post.get("content", "")
            badge = f" `{post_type}`" if post_type else ""
            lines.append(f"### {i}. {platform}{badge}")
            lines.append("")
            lines.append(content)
            lines.append("")

    # â”€â”€ Transcript â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    lines.append("---")
    lines.append("")
    lines.append("## ğŸ“ æ–‡å­—èµ·ã“ã—")
    lines.append("")

    for rec in recordings:
        duration_str = format_timestamp(rec["duration"])
        lines.append(f"### {rec['time']} Recording ({duration_str})")
        lines.append("")

        clean_segments = filter_hallucinated_segments(rec["segments"])
        for seg in clean_segments:
            ts = format_timestamp(seg["start"])
            text = seg["text"].strip()
            if text:
                lines.append(f"`[{ts}]` {text}")
        lines.append("")

    return "\n".join(lines)


def collect_date_transcripts(manifest: dict, date: str) -> list[dict]:
    """Collect all transcripts for a given date from manifest."""
    results = []
    for mp3_name, entry in manifest["transcribed"].items():
        if entry.get("date") != date:
            continue
        results.append(
            {
                "time": entry["time"],
                "time_full": entry.get("time_full", entry["time"] + ":00"),
                "segments": entry.get("segments", []),
                "transcript_text": entry.get("transcript_text", ""),
                "duration": entry.get("duration_seconds", 0),
                "duration_min": entry.get("duration_seconds", 0) / 60,
                "mp3_name": mp3_name,
            }
        )
    return results


def phase3_generate_markdown(
    manifest: dict, dates_to_regenerate: set[str], client: openai.OpenAI
):
    """Phase 3: Generate Markdown reports with GPT-4o summaries."""
    MARKDOWN_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    profile = load_user_profile()  # Load once; accumulates across dates

    for date in sorted(dates_to_regenerate):
        logger.info(f"Generating Markdown for {date}")

        recordings = collect_date_transcripts(manifest, date)
        recordings.sort(key=lambda r: r["time"])

        if not recordings:
            logger.warning(f"  No transcripts found for {date}, skipping")
            continue

        logger.info(f"  {len(recordings)} recording(s) for this date")

        # Guard: don't overwrite an existing Markdown with fewer recordings
        md_path = MARKDOWN_OUTPUT_DIR / f"voicememo-{date}.md"
        if md_path.exists():
            existing_count = md_path.read_text(encoding="utf-8").count("### ")
            if existing_count > len(recordings):
                logger.warning(
                    f"  Existing Markdown has {existing_count} recordings, "
                    f"but only {len(recordings)} available now â€” skipping to avoid data loss"
                )
                continue

        notify("Voice Memo", f"Phase 3: {date} ã®è¦ç´„ã¨Markdownç”Ÿæˆä¸­...")
        update_status("processing", 3, "è¦ç´„ãƒ»Markdownç”Ÿæˆä¸­", date, len(dates_to_regenerate), list(sorted(dates_to_regenerate)).index(date))

        # Summarize with GPT-4o (pass accumulated profile for SNS post quality)
        try:
            summary_data = retry_with_backoff(
                lambda d=date, r=recordings: summarize_transcripts(client, d, r, profile=profile)
            )
        except Exception as e:
            logger.warning(
                f"  GPT-4o summarization failed ({e}), generating without summary"
            )
            summary_data = {
                "summary": "(è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚¯ã‚©ãƒ¼ã‚¿å¾©å¸°å¾Œã«å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚)",
                "highlights": [],
            }

        # Generate and write Markdown
        try:
            md_content = generate_markdown(date, recordings, summary_data)
            md_path = MARKDOWN_OUTPUT_DIR / f"voicememo-{date}.md"
            md_path.write_text(md_content, encoding="utf-8")
            logger.info(f"  Written: {md_path}")

            # Update and save the user profile with insights from today
            try:
                logger.info("  Updating user profile...")
                profile = update_user_profile(client, date, summary_data, profile)
                save_user_profile(profile)
                logger.info(f"  Profile updated ({len(profile.get('frequent_topics', []))} topics, "
                            f"{len(profile.get('example_posts', []))} post examples)")
            except Exception as pe:
                logger.warning(f"  Profile update skipped: {pe}")

        except Exception as e:
            logger.error(
                f"  Failed to generate Markdown for {date}: {e}", exc_info=True
            )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main orchestration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


LOCK_FILE = Path("/tmp/voicememo-processor.lock")


def acquire_lock() -> bool:
    """Prevent concurrent runs. Returns True if lock acquired."""
    if LOCK_FILE.exists():
        try:
            pid = int(LOCK_FILE.read_text().strip())
            # Check if process is still running
            os.kill(pid, 0)
            return False  # Another instance is running
        except (ValueError, ProcessLookupError, PermissionError):
            LOCK_FILE.unlink(missing_ok=True)  # Stale lock

    LOCK_FILE.write_text(str(os.getpid()))
    return True


def release_lock():
    LOCK_FILE.unlink(missing_ok=True)


def _init_env():
    """Common initialization: logging, env, manifest."""
    setup_logging()
    dotenv.load_dotenv(SCRIPT_DIR / ".env")
    
    # Fallback for the original author
    author_env = Path.home() / "Documents/GitHub/llm-knowledge-base/.env"
    if not os.environ.get("OPENAI_API_KEY") and author_env.exists():
        dotenv.load_dotenv(author_env)
        
    if not os.environ.get("OPENAI_API_KEY"):
        logger.error("OPENAI_API_KEY not found in .env (needed for GPT-4o summary)")
        return None
    manifest = load_manifest()
    manifest = migrate_manifest(manifest)
    return manifest


def _finish(all_dates: set[str], remaining: list):
    """Send final notification based on results."""
    if all_dates and not remaining:
        dates_str = ", ".join(sorted(all_dates))
        update_status("done", phase_label=f"å®Œäº†: {dates_str}")
        notify(
            "Voice Memo",
            f"å…¨å‡¦ç†å®Œäº†! {dates_str} ã®Markdownã‚’ç”Ÿæˆã—ã¾ã—ãŸ",
            sound="Hero",
        )
    elif all_dates and remaining:
        dates_str = ", ".join(sorted(all_dates))
        update_status("done", phase_label=f"ä¸€éƒ¨å®Œäº†: {len(remaining)}ä»¶æœªå‡¦ç†")
        notify(
            "Voice Memo",
            f"{dates_str} ã®Markdownã‚’ç”Ÿæˆï¼ˆ{len(remaining)}ä»¶ã¯æ¬¡å›ãƒªãƒˆãƒ©ã‚¤ï¼‰",
            sound="Glass",
        )
    elif remaining:
        update_status("done", phase_label=f"{len(remaining)}ä»¶æœªå‡¦ç†")
        notify(
            "Voice Memo",
            f"âš  {len(remaining)}ä»¶ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã€‚æ¬¡å›è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™",
            sound="Basso",
        )
    else:
        update_status("idle", phase_label="æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãªã—")


def main():
    setup_logging()

    # Acquire lock to prevent concurrent runs
    if not acquire_lock():
        logger.info("Another instance is running, exiting")
        return

    try:
        # Wait for USB volume to stabilize (if triggered by launchd)
        time.sleep(3)

        logger.info("=" * 60)
        logger.info("Voice Memo Processor v2 started")
        update_status("starting", phase_label="åˆæœŸåŒ–ä¸­...")

        manifest = _init_env()
        if manifest is None:
            return

        # Phase 1: Copy WAV â†’ MP3 to Google Drive (only if USB mounted)
        dates_from_copy = phase1_copy_from_usb(manifest)

        # Phase 2: Transcribe untranscribed MP3s from Google Drive (local mlx-whisper)
        dates_from_transcribe = phase2_transcribe(manifest)

        # Check for remaining untranscribed files (failures in this run)
        remaining = discover_untranscribed_mp3s(manifest)

        # Phase 3: Generate Markdown for all affected dates
        all_dates = dates_from_copy | dates_from_transcribe
        if all_dates:
            client = openai.OpenAI()
            phase3_generate_markdown(manifest, all_dates, client)
        else:
            logger.info("No new data to generate Markdown for")

        logger.info("Processing complete")
        logger.info("=" * 60)
        _finish(all_dates, remaining)

    finally:
        release_lock()


def retry():
    """Retry failed transcriptions (Phase 2 + 3 only). No USB needed."""
    setup_logging()

    if not acquire_lock():
        logger.info("Another instance is running, exiting")
        return

    try:
        logger.info("=" * 60)
        logger.info("Voice Memo Processor â€” RETRY mode")
        update_status("starting", phase_label="ãƒªãƒˆãƒ©ã‚¤ä¸­...")

        manifest = _init_env()
        if manifest is None:
            return

        # Check what's pending
        untranscribed = discover_untranscribed_mp3s(manifest)
        if not untranscribed:
            logger.info("No untranscribed files to retry")
            notify("Voice Memo", "ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡ãªã— â€” å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿")
            update_status("idle", phase_label="å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿")
            return

        logger.info(f"Retrying {len(untranscribed)} untranscribed file(s)")
        notify("Voice Memo", f"ãƒªãƒˆãƒ©ã‚¤é–‹å§‹: {len(untranscribed)}ä»¶ã®æ–‡å­—èµ·ã“ã—")

        # Phase 2: Transcribe
        dates_from_transcribe = phase2_transcribe(manifest)

        # Check remaining
        remaining = discover_untranscribed_mp3s(manifest)

        # Phase 3: Generate Markdown
        if dates_from_transcribe:
            client = openai.OpenAI()
            phase3_generate_markdown(manifest, dates_from_transcribe, client)

        logger.info("Retry complete")
        logger.info("=" * 60)
        _finish(dates_from_transcribe, remaining)

    finally:
        release_lock()


def status():
    """Show current processing status."""
    manifest = load_manifest()
    manifest = migrate_manifest(manifest)

    copied = set(e["mp3_name"] for e in manifest["copied"].values())
    transcribed = set(manifest["transcribed"].keys())
    untranscribed = copied - transcribed

    print(f"ğŸ“Š Voice Memo Status")
    print(f"  Copied:        {len(copied)} files")
    print(f"  Transcribed:   {len(transcribed)} files")
    print(f"  Untranscribed: {len(untranscribed)} files")

    if untranscribed:
        print(f"\nâ³ Pending files:")
        for f in sorted(untranscribed):
            # Find date from manifest
            for _, entry in manifest["copied"].items():
                if entry["mp3_name"] == f:
                    print(f"  {entry['date']} {entry['time']} â€” {f}")
                    break

    # Check staging dir
    if STAGING_DIR.exists():
        staging_files = list(STAGING_DIR.glob("*.mp3"))
        if staging_files:
            print(f"\nğŸ“ Staging files: {len(staging_files)}")
            for sf in sorted(staging_files):
                size_mb = sf.stat().st_size / (1024 * 1024)
                print(f"  {sf.name} ({size_mb:.1f} MB)")


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        cmd = sys.argv[1]
        if cmd == "retry":
            retry()
        elif cmd == "status":
            status()
        else:
            print(f"Usage: {sys.argv[0]} [retry|status]")
            print(f"  (no args)  Full pipeline (Phase 1+2+3)")
            print(f"  retry      Retry failed transcriptions (Phase 2+3)")
            print(f"  status     Show processing status")
            sys.exit(1)
    else:
        main()
